{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Unpack ETL files",
   "id": "f8fab94252f7ab8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T11:19:20.391250Z",
     "start_time": "2025-09-15T11:19:18.849227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from openai.types.beta.threads import image_file\n",
    "\n",
    "project_root = Path().resolve()\n",
    "etl_dir = project_root / \"data\" / \"ETL8G\"\n",
    "unpack_script = project_root / \"data\" / \"unpack_etlcdb\" / \"unpack_etlcdb\" / \"unpack.py\"\n",
    "\n",
    "files = os.listdir(etl_dir)\n",
    "\n",
    "for file in files:\n",
    "    if file != \"ETL8INFO\":\n",
    "        input_file = etl_dir / file\n",
    "        cmd = f'python {unpack_script} {input_file}'\n",
    "        print(\"Running:\", cmd)\n",
    "        # os.system(cmd)\n",
    "\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_01\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_01_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_02\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_02_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_03\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_03_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_04\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_04_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_05\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_05_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_06\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_06_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_07\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_07_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_08\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_08_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_09\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_09_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_10\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_10_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_11\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_11_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_12\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_12_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_13\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_13_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_14\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_14_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_15\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_15_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_16\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_16_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_17\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_17_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_18\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_18_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_19\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_19_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_20\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_20_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_21\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_21_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_22\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_22_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_23\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_23_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_24\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_24_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_25\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_25_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_26\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_26_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_27\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_27_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_28\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_28_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_29\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_29_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_30\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_30_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_31\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_31_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_32\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_32_unpack\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_33\n",
      "Running: python C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\unpack_etlcdb\\unpack_etlcdb\\unpack.py C:\\Users\\alicj\\PycharmProjects\\KanjiRecognitionModel\\data\\ETL8G\\ETL8G_33_unpack\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Saving labels to list",
   "id": "7f6d9ff940d65629"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T20:36:13.383749Z",
     "start_time": "2025-09-16T20:36:12.920768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_to_labels = Path().resolve()/ \"data\" / \"ETL8G\"/ \"ETL8G_01_unpack\"/\"meta.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(path_to_labels)\n",
    "\n",
    "labels = labels_df[\"char\"]\n",
    "labels = labels.tolist()\n"
   ],
   "id": "e81ffe2bfd5e0650",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T20:36:16.184745Z",
     "start_time": "2025-09-16T20:36:16.150231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_labels = labels.copy()\n",
    "labels_copy = all_labels.copy()\n",
    "\n",
    "for i in range(31):\n",
    "    labels_copy_2 = labels_copy.copy()\n",
    "    all_labels.extend(labels_copy_2)\n",
    "\n",
    "all_labels.extend(labels_copy[:956])"
   ],
   "id": "6d26776685765acf",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T11:20:12.877192Z",
     "start_time": "2025-09-15T11:20:12.815634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "#\n",
    "# le = LabelEncoder()\n",
    "# labels_int = le.fit_transform(labels)\n",
    "#\n",
    "# print(labels_int[:10])        # now numbers like [0, 1, 0, 2, ...]\n",
    "# print(le.classes_[:10])       # the mapping back to original labels\n"
   ],
   "id": "c7dbfc3c177523e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 415 301 281 919 162 611 118 588 111]\n",
      "['あ' 'い' 'う' 'え' 'お' 'か' 'が' 'き' 'ぎ' 'く']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T11:45:37.913482Z",
     "start_time": "2025-09-15T11:45:37.910185Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ce0b07193c4aad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T20:36:25.486419Z",
     "start_time": "2025-09-16T20:36:21.910267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# go through each folder\n",
    "path_label_list = []\n",
    "etl_dir = Path().resolve() / \"data\" / \"ETL8G\"\n",
    "for folder in os.listdir(etl_dir):\n",
    "    if \"unpack\" in folder:\n",
    "        folder_path = os.path.join(etl_dir, folder)\n",
    "\n",
    "        # go through each png in folder\n",
    "        for fname in os.listdir(folder_path):\n",
    "            if fname.endswith(\".png\"):\n",
    "                fpath = os.path.join(folder_path, fname)\n",
    "                # take filename without extension\n",
    "                idx = int(os.path.splitext(fname)[0])\n",
    "                # compute label\n",
    "                label = idx % 956\n",
    "                path_label_list.append((fpath, label))\n",
    "\n",
    "print(path_label_list[956])\n"
   ],
   "id": "80d1bbda49220738",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('C:\\\\Users\\\\alicj\\\\PycharmProjects\\\\KanjiRecognitionModel\\\\data\\\\ETL8G\\\\ETL8G_01_unpack\\\\00956.png', 0)\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T20:36:28.142829Z",
     "start_time": "2025-09-16T20:36:28.127809Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(path_label_list))",
   "id": "eb7d4e46c0e8301a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153916\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T20:37:55.983347Z",
     "start_time": "2025-09-16T20:37:55.975840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(labels[1])\n",
    "print(path_label_list[1912])"
   ],
   "id": "dc1729b2fcd018e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "愛\n",
      "('C:\\\\Users\\\\alicj\\\\PycharmProjects\\\\KanjiRecognitionModel\\\\data\\\\ETL8G\\\\ETL8G_01_unpack\\\\01912.png', 0)\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Saving images",
   "id": "c90cef8814ea4d48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T20:49:22.420129Z",
     "start_time": "2025-09-16T20:49:18.919685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_paths = []\n",
    "img_dir_path = Path().resolve()/ \"data\" / \"ETL8G\"\n",
    "\n",
    "files = os.listdir(img_dir_path)\n",
    "for file in files:\n",
    "    if \"unpack\" in file:\n",
    "        unpack_dir = img_dir_path / file\n",
    "        img_files = os.listdir(unpack_dir)\n",
    "        for img_file in img_files:\n",
    "            if img_file != 'meta.csv':\n",
    "                img_path = unpack_dir / img_file\n",
    "                image_paths.append(img_path)\n",
    "\n",
    "# in the last dir there are only 955 images\n",
    "\n"
   ],
   "id": "96a367410b25f080",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create a CNN",
   "id": "c2843c9b90a56479"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T20:49:24.308395Z",
     "start_time": "2025-09-16T20:49:24.301383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(image_paths))\n",
    "print(len(labels_int))"
   ],
   "id": "e6fd226cd6235692",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153916\n",
      "153916\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T11:20:07.763945Z",
     "start_time": "2025-09-15T11:20:07.756945Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b5009b8adcab538f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T11:20:09.214740Z",
     "start_time": "2025-09-15T11:20:09.208844Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(labels))",
   "id": "be43b50735ec8f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153916\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset class",
   "id": "368a45cb69af6690"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:22:11.112875Z",
     "start_time": "2025-09-16T21:22:11.104214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        path = item[0]\n",
    "        img = Image.open(path)\n",
    "        img=img.convert(\"L\")\n",
    "        img = T.ToTensor()(img)\n",
    "        label =item[1]\n",
    "        # img.show()\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n"
   ],
   "id": "2e1e0e40dfe36b6e",
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:22:19.821253Z",
     "start_time": "2025-09-16T21:22:19.814835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = ImageDataset(path_label_list)\n",
    "img, lab = a[0]\n",
    "# print(img.size)\n",
    "print(lab)\n",
    "print(type(img), img.shape, lab)"
   ],
   "id": "ade7c40ecfcc3ba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "<class 'torch.Tensor'> torch.Size([1, 127, 128]) tensor(0)\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Splitting the data into train, val, test sets",
   "id": "92b1874541ceaf8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:22:24.356303Z",
     "start_time": "2025-09-16T21:22:24.202143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# first split train vs temp (val+test)\n",
    "train_data, temp_data = train_test_split(path_label_list, test_size=0.3, random_state=42, stratify=[d[1] for d in path_label_list]) # used tratify to preserve the same class proportions\n",
    "\n",
    "# then split temp into val and test\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=[d[1] for d in temp_data])\n"
   ],
   "id": "526c15f1445562f2",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:22:24.752504Z",
     "start_time": "2025-09-16T21:22:24.748113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = ImageDataset(train_data)\n",
    "val_dataset   = ImageDataset(val_data)\n",
    "test_dataset  = ImageDataset(test_data)\n"
   ],
   "id": "dae3c9ca35918301",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Loader",
   "id": "b75ff2385de8a8bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:22:27.970736Z",
     "start_time": "2025-09-16T21:22:27.963613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32)\n"
   ],
   "id": "66a2aab255130944",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test CNN",
   "id": "390a53b0fb04c2a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:24:51.346786Z",
     "start_time": "2025-09-16T21:24:51.341518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # 1 input channel (grayscale), 8 filters\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)   # reduces size by half\n",
    "        # Flattened size after pool (assuming 64x64 input): 8 * 32 * 32\n",
    "        self.fc1 = nn.Linear(32256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # conv → relu → pool\n",
    "        x = x.view(x.size(0), -1)             # flatten\n",
    "        x = self.fc1(x)                       # fully connected\n",
    "        return x\n"
   ],
   "id": "ec0597d2bcf13537",
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:24:52.050576Z",
     "start_time": "2025-09-16T21:24:51.685929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example: suppose you have 100 kanji classes\n",
    "model = SimpleCNN(num_classes=956)\n",
    "\n",
    "# One fake batch: 32 grayscale images, 64x64 each\n",
    "x = torch.randn(32, 1, 64, 64)\n",
    "out = model(x)\n",
    "\n",
    "print(out.shape)  # torch.Size([32, 100]) → 32 predictions, 100 classes\n"
   ],
   "id": "b533d0162f988710",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x8192 and 32256x956)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[135]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# One fake batch: 32 grayscale images, 64x64 each\u001B[39;00m\n\u001B[32m      5\u001B[39m x = torch.randn(\u001B[32m32\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m64\u001B[39m, \u001B[32m64\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m out = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(out.shape)  \u001B[38;5;66;03m# torch.Size([32, 100]) → 32 predictions, 100 classes\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[134]\u001B[39m\u001B[32m, line 17\u001B[39m, in \u001B[36mSimpleCNN.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     15\u001B[39m x = \u001B[38;5;28mself\u001B[39m.pool(F.relu(\u001B[38;5;28mself\u001B[39m.conv1(x)))  \u001B[38;5;66;03m# conv → relu → pool\u001B[39;00m\n\u001B[32m     16\u001B[39m x = x.view(x.size(\u001B[32m0\u001B[39m), -\u001B[32m1\u001B[39m)             \u001B[38;5;66;03m# flatten\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfc1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m                       \u001B[38;5;66;03m# fully connected\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: mat1 and mat2 shapes cannot be multiplied (32x8192 and 32256x956)"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:31:20.817794Z",
     "start_time": "2025-09-16T21:25:38.246830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(3):  # 3 training epochs\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()         # reset gradients\n",
    "        outputs = model(images)       # forward pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()               # backward pass\n",
    "        optimizer.step()              # update weights\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ],
   "id": "5d4db267150c3e75",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[138]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m images, labels \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[32m      7\u001B[39m     optimizer.zero_grad()         \u001B[38;5;66;03m# reset gradients\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m     outputs = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m       \u001B[38;5;66;03m# forward pass\u001B[39;00m\n\u001B[32m      9\u001B[39m     loss = criterion(outputs, labels)\n\u001B[32m     10\u001B[39m     loss.backward()               \u001B[38;5;66;03m# backward pass\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[134]\u001B[39m\u001B[32m, line 15\u001B[39m, in \u001B[36mSimpleCNN.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.pool(F.relu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m))  \u001B[38;5;66;03m# conv → relu → pool\u001B[39;00m\n\u001B[32m     16\u001B[39m     x = x.view(x.size(\u001B[32m0\u001B[39m), -\u001B[32m1\u001B[39m)             \u001B[38;5;66;03m# flatten\u001B[39;00m\n\u001B[32m     17\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.fc1(x)                       \u001B[38;5;66;03m# fully connected\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001B[39m, in \u001B[36mConv2d.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    547\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m548\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001B[39m, in \u001B[36mConv2d._conv_forward\u001B[39m\u001B[34m(self, input, weight, bias)\u001B[39m\n\u001B[32m    531\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.padding_mode != \u001B[33m\"\u001B[39m\u001B[33mzeros\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    532\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.conv2d(\n\u001B[32m    533\u001B[39m         F.pad(\n\u001B[32m    534\u001B[39m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m._reversed_padding_repeated_twice, mode=\u001B[38;5;28mself\u001B[39m.padding_mode\n\u001B[32m   (...)\u001B[39m\u001B[32m    541\u001B[39m         \u001B[38;5;28mself\u001B[39m.groups,\n\u001B[32m    542\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m543\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    544\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgroups\u001B[49m\n\u001B[32m    545\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "53b800e396bdd5b0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
