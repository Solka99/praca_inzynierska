{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:43:13.110644Z",
     "start_time": "2025-12-26T18:43:13.097508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve()"
   ],
   "id": "d846d3906d09bdbf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-26T18:43:19.218733Z",
     "start_time": "2025-12-26T18:43:16.549845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_to_labels = Path().resolve()/ \"data\" / \"ETL8G\"/ \"ETL8G_01_unpack\"/\"meta.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(path_to_labels)\n",
    "\n",
    "labels = labels_df[\"char\"]\n",
    "labels = labels.tolist()\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:43:19.258206Z",
     "start_time": "2025-12-26T18:43:19.235886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_labels = labels.copy()\n",
    "labels_copy = all_labels.copy()\n",
    "\n",
    "for i in range(31):\n",
    "    labels_copy_2 = labels_copy.copy()\n",
    "    all_labels.extend(labels_copy_2)\n",
    "\n",
    "all_labels.extend(labels_copy[:956])"
   ],
   "id": "c1dcded390e1b5c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:43:19.952924Z",
     "start_time": "2025-12-26T18:43:19.292903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# go through each folder\n",
    "path_label_list = []\n",
    "etl_dir = Path().resolve() / \"data\" / \"ETL8G\"\n",
    "for folder in os.listdir(etl_dir):\n",
    "    if \"unpack\" in folder:\n",
    "        folder_path = os.path.join(etl_dir, folder)\n",
    "\n",
    "        # go through each png in folder\n",
    "        for fname in os.listdir(folder_path):\n",
    "            if fname.endswith(\".png\"):\n",
    "                fpath = os.path.join(folder_path, fname)\n",
    "                # take filename without extension\n",
    "                idx = int(os.path.splitext(fname)[0])\n",
    "                # compute label\n",
    "                label = idx % 956\n",
    "                path_label_list.append((fpath, label))\n",
    "\n",
    "print(path_label_list[956])\n"
   ],
   "id": "63488a9b848010c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('C:\\\\Users\\\\alicj\\\\PycharmProjects\\\\KanjiRecognitionModel\\\\data\\\\ETL8G\\\\ETL8G_01_unpack\\\\00956.png', 0)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:43:19.978304Z",
     "start_time": "2025-12-26T18:43:19.970343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# label_index_list = []\n",
    "# for path, label in path_label_list:\n",
    "#     label_index_list.append(label)\n",
    "# print(label_index_list[95])"
   ],
   "id": "f2002fad77671edf",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-26T18:43:20.034446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.data[idx]\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = T.ToTensor()(img)\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n"
   ],
   "id": "ab6397a3370ccfb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T15:08:30.490138Z",
     "start_time": "2025-12-05T15:08:30.472217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "imageDataset = ImageDataset(path_label_list, transform)\n",
    "img, lab = imageDataset[0]\n",
    "# print(img.size)\n",
    "print(lab)\n",
    "print(type(img), img.shape, lab)"
   ],
   "id": "579788492982aee5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "<class 'torch.Tensor'> torch.Size([1, 64, 64]) tensor(0)\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T14:36:50.144154Z",
     "start_time": "2025-12-05T14:36:48.380262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# first split train vs temp (val+test)\n",
    "train_data, temp_data = train_test_split(path_label_list[:70000], test_size=0.3, random_state=42, stratify=[d[1] for d in path_label_list[:70000]]) # used stratify to preserve the same class proportions\n",
    "\n",
    "# then split temp into val and test\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=[d[1] for d in temp_data])\n"
   ],
   "id": "e9a2a820339c339c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T14:36:50.266679Z",
     "start_time": "2025-12-05T14:36:50.255032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = ImageDataset(train_data, transform)\n",
    "val_dataset   = ImageDataset(val_data, transform)\n",
    "test_dataset  = ImageDataset(test_data, transform)\n"
   ],
   "id": "a417dc189f9d9439",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T14:36:50.311795Z",
     "start_time": "2025-12-05T14:36:50.304370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, num_workers=0)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, num_workers=0)\n"
   ],
   "id": "bb291528dea952c1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T14:40:46.185427Z",
     "start_time": "2025-12-05T14:40:46.172895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ],
   "id": "cf83c98d20c4a3f7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T14:40:46.836661Z",
     "start_time": "2025-12-05T14:40:46.824661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNN_Improved(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # 64x64 -> 32x32\n",
    "        self.block1 = ConvBlock(1, 32)\n",
    "        # 32x32 -> 16x16\n",
    "        self.block2 = ConvBlock(32, 64)\n",
    "        # 16x16 -> 8x8\n",
    "        self.block3 = ConvBlock(64, 128)\n",
    "\n",
    "        self.gap  = nn.AdaptiveAvgPool2d(1)   # 8x8 -> 1x1\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.fc   = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)          # [B, 128, 8, 8]\n",
    "        x = self.gap(x)             # [B, 128, 1, 1]\n",
    "        x = torch.flatten(x, 1)     # [B, 128]\n",
    "        x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "id": "1fe271957d9ef7a7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T14:42:49.580499Z",
     "start_time": "2025-12-05T14:42:49.525732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = CNN_Improved(956)\n",
    "model.load_state_dict(torch.load(\"best_model3.pt\", map_location=\"cpu\"))\n",
    "model.eval()"
   ],
   "id": "b93ce90cd6a36d95",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Improved(\n",
       "  (block1): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (block2): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (block3): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (drop): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=128, out_features=956, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T14:55:59.009468Z",
     "start_time": "2025-12-05T14:54:28.496648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "correct, total =0, 0\n",
    "test_loss = 0.0\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "preds =[]\n",
    "with torch.no_grad():\n",
    "    for x,y in test_loader:\n",
    "        logits = model(x)\n",
    "        test_loss = loss_fn(logits, y).item() * x.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        preds.append(pred)\n",
    "        correct+= (pred==y).sum().item()\n",
    "        total += x.size(0)\n",
    "print(f\"Test acc: {100*correct/total:.2f}% | Test loss: {test_loss/total:.4f}\")"
   ],
   "id": "64cf19070d0947dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 95.10% | Test loss: 0.0001\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T15:21:50.856618Z",
     "start_time": "2025-12-05T15:20:30.651858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(\"cpu\")\n",
    "        labels = labels.to(\"cpu\")\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "print(len(all_labels), len(all_preds))  # powinno być to samo\n"
   ],
   "id": "207c93d32f7814df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500 10500\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-05T15:22:42.252755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "#\n",
    "# # preds  → np.array z predykcjami modelu\n",
    "# # targets → np.array z prawdziwymi etykietami\n",
    "# # class_names → lista nazw klas, np. [\"日\",\"本\",\"人\",...]\n",
    "#\n",
    "# cm = confusion_matrix(all_labels, all_preds, normalize=\"true\")\n",
    "#\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "#\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# disp.plot(cmap=\"Blues\", xticks_rotation=45, colorbar=True)\n",
    "#\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ],
   "id": "4422deb7ef8a372a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "632fbde129354a8a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
