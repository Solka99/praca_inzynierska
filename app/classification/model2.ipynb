{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Unpack ETL files",
   "id": "f8fab94252f7ab8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from openai.types.beta.threads import image_file\n",
    "from pandas.core.common import random_state\n",
    "\n",
    "project_root = Path().resolve()\n",
    "etl_dir = project_root / \"data\" / \"ETL8G\"\n",
    "unpack_script = project_root / \"data\" / \"unpack_etlcdb\" / \"unpack_etlcdb\" / \"unpack.py\"\n",
    "\n",
    "files = os.listdir(etl_dir)\n",
    "\n",
    "for file in files:\n",
    "    if file != \"ETL8INFO\":\n",
    "        input_file = etl_dir / file\n",
    "        cmd = f'python {unpack_script} {input_file}'\n",
    "        print(\"Running:\", cmd)\n",
    "        # os.system(cmd)\n",
    "\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Saving labels to list",
   "id": "7f6d9ff940d65629"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_to_labels = Path().resolve()/ \"data\" / \"ETL8G\"/ \"ETL8G_01_unpack\"/\"meta.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(path_to_labels)\n",
    "\n",
    "labels = labels_df[\"char\"]\n",
    "labels = labels.tolist()\n"
   ],
   "id": "e81ffe2bfd5e0650",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_labels = labels.copy()\n",
    "labels_copy = all_labels.copy()\n",
    "\n",
    "for i in range(31):\n",
    "    labels_copy_2 = labels_copy.copy()\n",
    "    all_labels.extend(labels_copy_2)\n",
    "\n",
    "all_labels.extend(labels_copy[:956])"
   ],
   "id": "6d26776685765acf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# go through each folder\n",
    "path_label_list = []\n",
    "etl_dir = Path().resolve() / \"data\" / \"ETL8G\"\n",
    "for folder in os.listdir(etl_dir):\n",
    "    if \"unpack\" in folder:\n",
    "        folder_path = os.path.join(etl_dir, folder)\n",
    "\n",
    "        # go through each png in folder\n",
    "        for fname in os.listdir(folder_path):\n",
    "            if fname.endswith(\".png\"):\n",
    "                fpath = os.path.join(folder_path, fname)\n",
    "                # take filename without extension\n",
    "                idx = int(os.path.splitext(fname)[0])\n",
    "                # compute label\n",
    "                label = idx % 956\n",
    "                path_label_list.append((fpath, label))\n",
    "\n",
    "print(path_label_list[956])\n"
   ],
   "id": "80d1bbda49220738",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(len(path_label_list))",
   "id": "eb7d4e46c0e8301a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(labels[1])\n",
    "print(path_label_list[1912])"
   ],
   "id": "dc1729b2fcd018e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset class",
   "id": "368a45cb69af6690"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.data[idx]\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = T.ToTensor()(img)\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n"
   ],
   "id": "2e1e0e40dfe36b6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "a = ImageDataset(path_label_list, transform)\n",
    "img, lab = a[0]\n",
    "# print(img.size)\n",
    "print(lab)\n",
    "print(type(img), img.shape, lab)"
   ],
   "id": "ade7c40ecfcc3ba1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img, label = a[5012]      # get transformed tensor (after __getitem__)\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ],
   "id": "1ed69edad3a8c5c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Splitting the data into train, val, test sets",
   "id": "92b1874541ceaf8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, temp_data = train_test_split(path_label_list, test_size=0.3, random_state=42, stratify=[d[1] for d in path_label_list]) # used stratify to preserve the same class proportions\n",
    "\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=[d[1] for d in temp_data])\n"
   ],
   "id": "526c15f1445562f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = ImageDataset(train_data, transform)\n",
    "val_dataset   = ImageDataset(val_data, transform)\n",
    "test_dataset  = ImageDataset(test_data, transform)\n"
   ],
   "id": "dae3c9ca35918301",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Loader",
   "id": "b75ff2385de8a8bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, num_workers=0)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, num_workers=0)\n"
   ],
   "id": "66a2aab255130944",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "TEST",
   "id": "c362e32410df6be6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "imgs, labels = next(iter(train_loader))\n",
    "print(imgs.shape)    # [32, 1, 64, 64]\n",
    "print(labels.shape)  # [32]\n"
   ],
   "id": "c8a694d7366381aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model training",
   "id": "220ad4d917470865"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ],
   "id": "6e961f96249d825a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CNN_Improved(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # 64x64 -> 32x32\n",
    "        self.block1 = ConvBlock(1, 32)\n",
    "        # 32x32 -> 16x16\n",
    "        self.block2 = ConvBlock(32, 64)\n",
    "        # 16x16 -> 8x8\n",
    "        self.block3 = ConvBlock(64, 128)\n",
    "\n",
    "        self.gap  = nn.AdaptiveAvgPool2d(1)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.fc   = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.gap(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "id": "7802f30d7bb51773",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "\n",
    "        preds = outputs.argmax(1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total_samples += batch_size\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    acc = total_correct / total_samples\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "num_classes = 956\n",
    "model = CNN_Improved(num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "best_acc = 0.0\n",
    "best_path = \"best_model3.pt\"\n",
    "checkpoint_path = \"cnn_kanji_checkpoint3.pt\"\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_train_samples = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "        total_train_samples += batch_size\n",
    "\n",
    "    avg_train_loss = running_loss / total_train_samples\n",
    "\n",
    "\n",
    "    val_loss, val_acc = eval_model(model, val_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "        f\"train_loss={avg_train_loss:.4f} | \"\n",
    "        f\"val_loss={val_loss:.4f} | \"\n",
    "        f\"val_acc={val_acc*100:.2f}%\"\n",
    "    )\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        print(f\"✅ New best model saved (acc={best_acc:.4f})\")\n",
    "\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"val_accuracies\": val_accuracies,\n",
    "        \"best_acc\": best_acc,\n",
    "        # przydatne hiperparametry:\n",
    "        \"num_classes\": num_classes,\n",
    "        \"learning_rate\": 2e-3,\n",
    "        \"label_smoothing\": 0.1,\n",
    "        \"model_name\": \"CNN_Improved_v1\",\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "print(\"✅ Training complete!\")\n",
    "print(f\"Best val_acc = {best_acc*100:.2f}%\")"
   ],
   "id": "bd82aa9f795d9ce6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(val_losses, label='Validation Loss', marker='o')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "275b408af6c96dc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load weights\n",
    "model = CNN_Improved(956)\n",
    "model.load_state_dict(torch.load(\"best_model3.pt\", map_location=\"cpu\"))\n",
    "model.eval()"
   ],
   "id": "f0e684b6adb90efe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tfm = T.Compose([\n",
    "    T.Resize((64,64)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5],[0.5])\n",
    "])\n"
   ],
   "id": "e3d45cd5f9c99534",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "correct, total = 0, 0\n",
    "test_loss = 0.0\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:              # <- your existing DataLoader\n",
    "        logits = model(x)\n",
    "        test_loss += loss_fn(logits, y).item() * x.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "print(f\"Test acc: {100*correct/total:.2f}% | Test loss: {test_loss/total:.4f}\")"
   ],
   "id": "523dfd44dc9c5690",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(x)\n",
    "    pred = logits.argmax(1).item()\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    confidence = probs[0, pred].item()\n",
    "\n",
    "print(f\"Predicted class index: {pred}  |  confidence: {confidence:.2f}\")\n"
   ],
   "id": "b5ab4675b6727112",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(f\"Predicted class: {pred} (conf: {confidence:.2f})\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ],
   "id": "89ff966d5eb57349",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
